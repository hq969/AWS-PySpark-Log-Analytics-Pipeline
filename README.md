# AWS PySpark Log Analytics

ğŸ” Real-time analytics pipeline using AWS + PySpark to analyze server logs.

## âš™ï¸ Tech Stack
- AWS Kinesis (Log ingestion)
- PySpark on AWS EMR (Streaming processing)
- S3 (Storage)
- Athena + Glue (Query layer)
- Streamlit (Dashboard)

## ğŸ“ Folder Structure 

```
aws-pyspark-log-analytics/
â”œâ”€â”€ README.md               # Project overview and setup guide
â”œâ”€â”€ data-generator/         # Python script to simulate and send logs to Kinesis
â”‚   â””â”€â”€ send_logs.py

â”œâ”€â”€ spark-jobs/             # PySpark ETL job for processing real-time logs
â”‚   â””â”€â”€ process_logs.py

â”œâ”€â”€ config/                 # Configuration files for stream, batch jobs, and schema
â”‚   â””â”€â”€ kinesis_config.json

â”œâ”€â”€ dashboard/              # Streamlit dashboard for visualizing processed logs
â”‚   â””â”€â”€ app.py

```

## ğŸš€ To Run
1. Deploy Kinesis Stream.
2. Run `data-generator/log_producer.py` to send logs.
3. Submit `streaming_job.py` on AWS EMR.
4. Query output using Athena.
5. Visualize with `streamlit run dashboard/streamlit_app.py`.
